{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "############## TENSORBOARD ########################\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# tensorboard --logdir=runs\n",
    "###################################################\n",
    "\n",
    "############## Confusionmatrix ########################\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Settings for the NeuralNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "all_classes = [\"white\", \"red\", \"green\", \"other\"]\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 25\n",
    "num_classes = len(all_classes)\n",
    "num_epochs = 150\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 1 == True ; 0 == False\n",
    "load_model_from_file = 0\n",
    "\n",
    "#Automatic Filename for loading and saving\n",
    "learning_rate_string = str(learning_rate).replace('.', '')\n",
    "MiddleFilename = f\"HS{hidden_size}NE{num_epochs}BS{batch_size}LR{learning_rate_string}\"\n",
    "EndFilename = \"HLS.pth\"\n",
    "FILE = f\"ColorNeuralNet{MiddleFilename}{EndFilename}\"\n",
    "\n",
    "\n",
    "#Manuel Filename for loading\n",
    "#FILE = \"ColorNeuralNetHS25NE1500HLSACC8775.pth\"\n",
    "#FILE = \"ColorNeuralNetHS25NE10BS10HLSACC9075.pth\"\n",
    "\n",
    "#Writer for Tensorboard\n",
    "writer = SummaryWriter(f'runs/{MiddleFilename}')\n",
    "\n",
    "#Paths for Datasets\n",
    "TRAININGDATASETHLS = \"TrainingDatasetHLS.txt\"\n",
    "TESTDATASETHLS = \"TestDatasetHLS.txt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NeuralNet Class\n",
    "\n",
    "The model will be trained on the H and L values because in the manuel ColorRecognition they are also the only values used to determine the colors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \"\"\"initializes NeuralNet\n",
    "\n",
    "        :param input_size: input_size of the first linear layer\n",
    "        :param hidden_size: input_size of the second linear layer\n",
    "        :param num_classes: number of total classes of type int\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"forwards values through neural net\n",
    "\n",
    "        :param x: value that will be forwarded\n",
    "        :return: returns modified value after passing every layer\n",
    "        \"\"\"\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Class for the dataset and the necessary classes for using it\n",
    "\n",
    "I created the dataset using random generated BGR values and then manually selecting the classes and saving them in a .txt. After that I transformed the BGR values to HSL.\n",
    "I wanted to see if the NeuralNet could learn from my perception of the colors. Thats the reason why I didnt create random red and green colors from a given interval. In the end the ColorNeuralNet is the worst from the 3 Recognitions. In conflusion, I personally think that maybe the dataset is to small for my approach on colorRecognition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ColorDataset(Dataset):\n",
    "    \"\"\"color dataset from .txt File\n",
    "\n",
    "    example of dataset: class_id,h,l --> 0,0.08333333333333333,0.9137254901960784\n",
    "\n",
    "    Attributes:\n",
    "\n",
    "    - n_samples --> number of rows/samples in dataset\n",
    "    - n_x_data --> hsl values of type ndarray\n",
    "    - n_y_data --> labels of type ndarray\n",
    "    - n_transform --> transform function (for example ToTensor)\n",
    "    \"\"\"\n",
    "    def __init__(self, DATASETPATH, transform=None):\n",
    "        \"\"\"initializes ColorDataset\n",
    "\n",
    "        :param DATASETPATH: datasetpath of type String\n",
    "        :param transform: transform function (for example ToTensor)\n",
    "        \"\"\"\n",
    "        # read with numpy\n",
    "        xy = np.loadtxt(DATASETPATH, delimiter=',', dtype=np.float32)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"get label and features from given index\n",
    "\n",
    "        if ColorDataset has a transform function the data will be transformed before returning\n",
    "\n",
    "        :param index: index of label and features of type int\n",
    "        :return: returns label and features as combined variable\n",
    "        \"\"\"\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Convert ndarrays to Tensors\n",
    "\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "\n",
    "class MulTransform:\n",
    "    \"\"\"multiply inputs with a given factor\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions for the training and testing phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def createConfusionMatrix(loader, model):\n",
    "    \"\"\"creates Confusionmatrix from given Dataloader and given Model\n",
    "\n",
    "    :param loader: An instance of the class ColorDataset\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :return: returns confusion matrix as figure\n",
    "    \"\"\"\n",
    "    y_pred = [] # save prediction\n",
    "    y_true = [] # save ground truth\n",
    "    model.to(device)\n",
    "    # iterate over data\n",
    "    for inputs, labels in loader:\n",
    "        output = model(inputs.to(device))  # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "\n",
    "        y_pred.extend(output)  # save prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels)  # save ground truth\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * len(all_classes), index=[i for i in all_classes],\n",
    "                         columns=[i for i in all_classes])\n",
    "    plt.figure(figsize=(21, 7))\n",
    "    return sn.heatmap(df_cm.round(4), annot=True).get_figure()\n",
    "\n",
    "\n",
    "def outputAcc(n_correct, n_wrong, color):\n",
    "    acc = 100.0 * n_correct / (n_wrong + n_correct)\n",
    "    print(f'Accuracy of the network on {color} colors: {acc} % ({n_correct}/{n_wrong + n_correct})\\n')\n",
    "\n",
    "\n",
    "def countPredictedColors(labels, predicted, n_correct_array, n_wrong_array):\n",
    "    \"\"\"compares the two tensors labels and predicted.\n",
    "    Counts how many elements of the two given tensors are the same\n",
    "\n",
    "    :param labels: tensor with class_id as its elements\n",
    "    :param predicted: tensor with class_id as its elements (return value of model)\n",
    "    :param n_correct_array: List[int] acts as counter for every right guess for each class\n",
    "    :param n_wrong_array: List[int] acts as counter for every wrong guess for each class\n",
    "    :return: returns updated n_correct_array and n_wrong_array\n",
    "    \"\"\"\n",
    "    for batchNumber in range(predicted.size(dim=0)):\n",
    "        if labels[batchNumber] == predicted[batchNumber]:\n",
    "            n_correct_array[predicted[batchNumber]] += 1\n",
    "        else:\n",
    "            n_wrong_array[labels[batchNumber]] += 1\n",
    "            print(f\"predicted: {predicted}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "            print(\"Wrong\\n\")\n",
    "\n",
    "    return n_correct_array, n_wrong_array\n",
    "\n",
    "\n",
    "def convertFloatTensorToLongTensor(floatTensor):\n",
    "    \"\"\"converts a float tensor to a long tensor\n",
    "\n",
    "    :param floatTensor: tensor of type float\n",
    "    :return: returns a tensor of type long\n",
    "    \"\"\"\n",
    "    # Axis correction\n",
    "    floatTensor = floatTensor.view(floatTensor.size(dim=0))\n",
    "    # Convert to LongTensor\n",
    "    longTensor = floatTensor.long()\n",
    "    return longTensor\n",
    "\n",
    "def load_model(model):\n",
    "    \"\"\"loads an initialized model from a given path\n",
    "\n",
    "    :param model: initialized model of type ColorNeuralNet.NeuralNet\n",
    "    :return: returns the fully loaded model\n",
    "    \"\"\"\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    model.load_state_dict(torch.load(FILE))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def dataloaderSetup(DATASETPATH, normalized):\n",
    "    \"\"\"setups the data_loader for the given DATASETPATH\n",
    "\n",
    "    :param DATASETPATH: String with the path to the dataset\n",
    "    :param normalized: Int acts as a boolean to indicate if the dataset is normalized (1 == True, 0 == False) --> only works for BGR values NOT for HSL\n",
    "    :return: returns the data_loader\n",
    "    \"\"\"\n",
    "    if normalized == 1:\n",
    "        composed = torchvision.transforms.Compose([ToTensor()])\n",
    "    else:\n",
    "        composed = torchvision.transforms.Compose([ToTensor(), MulTransform(1 / 255)])\n",
    "    dataset = ColorDataset(DATASETPATH, transform=composed)\n",
    "\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return train_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trainingPhase(model, criterion, optimizer, train_loader):\n",
    "    \"\"\"trains the given model with the given parameters.\n",
    "\n",
    "    iterates once through the train_loader in each epoch\n",
    "    and updates the weights in the model\n",
    "\n",
    "    After every quarter step update the acc and loss graph in Tensorboard\n",
    "    and after every epoch create Confusion matrix\n",
    "\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :param criterion: loss function from torch.nn.modules.loss (for Example CrossEntropyLoss)\n",
    "    :param optimizer: optimizer from torch.optim (for Example Adam)\n",
    "    :param train_loader: dataloader with Training dataset\n",
    "    :return: returns trained model of the class NeuralNet\n",
    "    \"\"\"\n",
    "    n_total_steps = len(train_loader)\n",
    "    n_total_steps_quarter = n_total_steps*.25\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (hsl, labels) in enumerate(train_loader):\n",
    "            model.to(device)\n",
    "\n",
    "            outputs = model(hsl.to(device))\n",
    "\n",
    "            labels = convertFloatTensorToLongTensor(labels)\n",
    "            loss = criterion(outputs.to(device), labels.to(device))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if (i + 1) % (n_total_steps_quarter) == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                ############## TENSORBOARD ########################\n",
    "                writer.add_scalar('training loss', running_loss / n_total_steps_quarter, epoch * n_total_steps + i)\n",
    "                running_accuracy = running_correct / n_total_steps_quarter / predicted.size(0)\n",
    "                writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
    "                running_correct = 0\n",
    "                running_loss = 0.0\n",
    "                writer.close()\n",
    "                ###################################################\n",
    "        # Save confusion matrix to Tensorboard\n",
    "        writer.add_figure(f\"Confusion matrix training from: {FILE}\", createConfusionMatrix(train_loader, model), epoch)\n",
    "        writer.close()\n",
    "\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    torch.save(model.state_dict(), FILE)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testingPhase of the NeuralNet\n",
    "we got 2 outputs to verify the efficiency of the model\n",
    "1 of them is the output in the console on every right guessed class\n",
    "and the other one creates a confusion matrix, which is visible in tensorboard.\n",
    "If tensorboard is used then countPredictedColors could be removed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testingPhase(model, test_loader):\n",
    "    \"\"\"tests the model\n",
    "\n",
    "    iterates once through the test_loader\n",
    "    and checks how many classes are correctly guessed\n",
    "\n",
    "    after that creates a Confusionmatrix visible in Tensorboard\n",
    "\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :param test_loader: dataloader with Test dataset\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        print(\"\\n\\nStarting with Testing!\")\n",
    "        n_correct_array = [0, 0, 0, 0]\n",
    "        n_wrong_array = [0, 0, 0, 0]\n",
    "\n",
    "        for hsl, labels in test_loader:\n",
    "            outputs = model(hsl.to(device))\n",
    "            labels = convertFloatTensorToLongTensor(labels)\n",
    "            labels.to(device)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_correct_array, n_wrong_array = countPredictedColors(labels, predicted, n_correct_array, n_wrong_array)\n",
    "\n",
    "        # Save confusion matrix to Tensorboard\n",
    "        writer.add_figure(f\"Confusion matrix testing from: {FILE}\", createConfusionMatrix(test_loader, model))\n",
    "        writer.close()\n",
    "\n",
    "        counter = 0\n",
    "        n_correct = 0\n",
    "        n_wrong = 0\n",
    "        for color in all_classes:\n",
    "            outputAcc(n_correct_array[counter], n_wrong_array[counter], color)\n",
    "            n_correct += n_correct_array[counter]\n",
    "            n_wrong += n_wrong_array[counter]\n",
    "            counter += 1\n",
    "        outputAcc(n_correct, n_wrong, \"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function to use all of the functions of above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "    if load_model_from_file == 1:\n",
    "        model = load_model(model)\n",
    "    else:\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        train_loader = dataloaderSetup(TRAININGDATASETHLS, 1)\n",
    "        model = trainingPhase(model, criterion, optimizer, train_loader)\n",
    "\n",
    "    test_loader = dataloaderSetup(TESTDATASETHLS, 1)\n",
    "    testingPhase(model, test_loader)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}