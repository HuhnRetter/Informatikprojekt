{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "############## TENSORBOARD ########################\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "# tensorboard --logdir=runs\n",
    "###################################################\n",
    "\n",
    "############## Confusionmatrix ########################\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Settings for the ConvNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#dml only works if there is an amd gpu\n",
    "device = torch.device(\"dml\")\n",
    "\n",
    "all_classes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",\n",
    "               \"G\", \"H\", \"I\", \"J\", \"K\", \"L\",\n",
    "               \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\",\n",
    "               \"S\", \"T\", \"U\", \"V\", \"W\", \"X\",\n",
    "               \"Y\", \"Z\"]\n",
    "\n",
    "# Parameter\n",
    "num_epochs = 10\n",
    "batch_size = 26\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 1 == True ; 0 == False\n",
    "load_model_from_file = 1\n",
    "\n",
    "#Automatic Filename for loading and saving\n",
    "learning_rate_string = str(learning_rate).replace('.', '')\n",
    "MiddleFilename = f\"NE{num_epochs}BS{batch_size}LR{learning_rate_string}\"\n",
    "EndFilename = \"LetterNeuralNet.pth\"\n",
    "FILE = f\"LetterNeuralNet{MiddleFilename}{EndFilename}\"\n",
    "\n",
    "\n",
    "#Manuel Filename for loading\n",
    "FILE = \"LetterNeuralNetNE10BS26LR0001LetterNeuralNet.pth\"\n",
    "\n",
    "#Writer for Tensorboard\n",
    "writer = SummaryWriter(f'runs/{MiddleFilename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the class for creating a Convnet\n",
    "\n",
    "conv2d(colorchannelsize, outputchannelsize, filtersize)\n",
    "\n",
    "W = input size\n",
    "F = filter size\n",
    "P = padding size\n",
    "S = stride size\n",
    "(W-F + 2P)/S+1 = Convolutional Layer Size\n",
    "\n",
    "\n",
    "example for the first feature extraction:  input image-> convolutional layer -> relu function -> pooling layer\n",
    "-> 1, 28, 28 -> outputchannelsize, (28-5)/1 + 1 = 24, 24 -> 6, 24, 24 -> -> 6, 24/2 = 12, 12\n",
    "\n",
    "after after the feature extraction the graph is flattened and 3 linear layers are being used for the class classification\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 1, 28, 28\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 12, 12\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 4, 4\n",
    "        x = x.view(-1, 16 * 4 * 4)           # -> n, 256\n",
    "        x = F.relu(self.fc1(x))              # -> n, 120\n",
    "        x = F.relu(self.fc2(x))              # -> n, 84\n",
    "        x = self.fc3(x)                      # -> n, 26\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper functions for the training and testing phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def createConfusionMatrix(loader, model):\n",
    "    \"\"\"creates Confusionmatrix from given Dataloader and given Model\n",
    "\n",
    "    :param loader: An instance of the class ColorDataset\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :return: returns confusion matrix as figure\n",
    "    \"\"\"\n",
    "    y_pred = [] # save prediction\n",
    "    y_true = [] # save ground truth\n",
    "    model.to(device)\n",
    "    # iterate over data\n",
    "    for inputs, labels in loader:\n",
    "        output = model(inputs.to(device))  # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "\n",
    "        y_pred.extend(output)  # save prediction\n",
    "\n",
    "        # labels transforms because labels start with 1\n",
    "        labels = torch.add(labels, -1)\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels)  # save ground truth\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) * len(all_classes), index=[i for i in all_classes],\n",
    "                         columns=[i for i in all_classes])\n",
    "    plt.figure(figsize=(21, 7))\n",
    "    return sn.heatmap(df_cm.round(4), annot=True).get_figure()\n",
    "\n",
    "def outputAcc(n_correct, n_wrong, letter):\n",
    "    acc = 100.0 * n_correct / (n_wrong + n_correct)\n",
    "    print(f'Accuracy of the network on {letter} letters: {acc} % ({n_correct}/{n_wrong + n_correct})\\n')\n",
    "\n",
    "\n",
    "def countPredictedLetters(labels, predicted, n_correct_array, n_wrong_array):\n",
    "    \"\"\"compares the two tensors labels and predicted.\n",
    "    Counts how many elements of the two given tensors are the same\n",
    "\n",
    "    :param labels: tensor with class_id as its elements\n",
    "    :param predicted: tensor with class_id as its elements (return value of model)\n",
    "    :param n_correct_array: List[int] acts as counter for every right guess for each class\n",
    "    :param n_wrong_array: List[int] acts as counter for every wrong guess for each class\n",
    "    :return: returns updated n_correct_array and n_wrong_array\n",
    "    \"\"\"\n",
    "    for batchNumber in range(predicted.size(dim=0)):\n",
    "        if labels[batchNumber] == predicted[batchNumber]:\n",
    "            n_correct_array[predicted[batchNumber]] += 1\n",
    "        else:\n",
    "            n_wrong_array[labels[batchNumber]] += 1\n",
    "            print(f\"predicted: {predicted}\")\n",
    "            print(f\"labels: {labels}\")\n",
    "            print(\"Wrong\\n\")\n",
    "\n",
    "    return n_correct_array, n_wrong_array\n",
    "\n",
    "\n",
    "def convertFloatTensorToLongTensor(floatTensor):\n",
    "    \"\"\"converts a float tensor to a long tensor\n",
    "\n",
    "    :param floatTensor: tensor of type float\n",
    "    :return: returns a tensor of type long\n",
    "    \"\"\"\n",
    "    # Axis correction\n",
    "    floatTensor = floatTensor.view(floatTensor.size(dim=0))\n",
    "    # Convert to LongTensor\n",
    "    longTensor = floatTensor.long()\n",
    "    return longTensor\n",
    "\n",
    "def load_model(model):\n",
    "    \"\"\"loads an initialized model from a given path\n",
    "\n",
    "    :param model: initialized model of type ColorNeuralNet.NeuralNet\n",
    "    :return: returns the fully loaded model\n",
    "    \"\"\"\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    model.load_state_dict(torch.load(FILE))\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "setup for both dataloader from the EMNIST dataset (only letters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dataloaderSetup():\n",
    "    \"\"\"setups both dataloader for the EMNIST datasets\n",
    "\n",
    "    :return: train_loader and test_loader of the EMNIST dataset\n",
    "    \"\"\"\n",
    "    # EMNIST dataset\n",
    "    train_dataset = torchvision.datasets.EMNIST(root='./data',  split='letters', transform=transforms.ToTensor(), train=True, download=True)\n",
    "    test_dataset = torchvision.datasets.EMNIST(root='./data', split='letters', transform=transforms.ToTensor(), train=False)\n",
    "    # Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "trainingphase of the NeuralNet if the setting are wrong setted.\n",
    "You could be overwriting your existing trained model so be careful"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trainingPhase(model, criterion, optimizer, train_loader):\n",
    "    \"\"\"trains the given model with the given parameters.\n",
    "\n",
    "    iterates once through the train_loader in each epoch\n",
    "    and updates the weights in the model\n",
    "\n",
    "    After every quarter step update the acc and loss graph in Tensorboard\n",
    "    and after every epoch create Confusion matrix\n",
    "\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :param criterion: loss function from torch.nn.modules.loss (for Example CrossEntropyLoss)\n",
    "    :param optimizer: optimizer from torch.optim (for Example Adam)\n",
    "    :param train_loader: dataloader with Training dataset\n",
    "    :return: returns trained model of the class NeuralNet\n",
    "    \"\"\"\n",
    "    n_total_steps = len(train_loader)\n",
    "    n_total_steps_quarter = n_total_steps * .1\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (letters, labels) in enumerate(train_loader):\n",
    "            #labels transforms because labels start with 1\n",
    "            labels = torch.add(labels, -1)\n",
    "            letters.to(device)\n",
    "            labels.to(device)\n",
    "            model.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(letters.to(device))\n",
    "            labels = convertFloatTensorToLongTensor(labels)\n",
    "            loss = criterion(outputs.to(device), labels.to(device))\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if (i + 1) % (n_total_steps_quarter) == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "                ############## TENSORBOARD ########################\n",
    "                writer.add_scalar('training loss', running_loss / n_total_steps_quarter, epoch * n_total_steps + i)\n",
    "                running_accuracy = running_correct / n_total_steps_quarter / predicted.size(0)\n",
    "                writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
    "                running_correct = 0\n",
    "                running_loss = 0.0\n",
    "                writer.close()\n",
    "                ###################################################\n",
    "        # Save confusion matrix to Tensorboard\n",
    "        writer.add_figure(f\"Confusion matrix training from: {FILE}\", createConfusionMatrix(train_loader, model), epoch)\n",
    "        writer.close()\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    torch.save(model.state_dict(), FILE)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "testingPhase of the NeuralNet we got 2 outputs to verify the efficiency of the model\n",
    "1 of them is the output in the console on every right guessed class\n",
    "and the other one creates a confusion matrix, which is visible in tensorboard.\n",
    "If tensorboard is used then countPredictedColors could be removed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def testingPhase(model, test_loader):\n",
    "    \"\"\"tests the model\n",
    "\n",
    "    iterates once through the test_loader\n",
    "    and checks how many classes are correctly guessed\n",
    "\n",
    "    after that creates a Confusionmatrix visible in Tensorboard\n",
    "\n",
    "    :param model: current model of the class NeuralNet\n",
    "    :param test_loader: dataloader with Test dataset\n",
    "    \"\"\"\n",
    "    device = \"cpu\"\n",
    "    with torch.no_grad():\n",
    "        print(\"\\n\\nStarting with Testing!\")\n",
    "        n_correct_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        n_wrong_array = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "        model.to(device)\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs.to(device))\n",
    "            labels = convertFloatTensorToLongTensor(labels)\n",
    "            # labels transforms because labels start with 1\n",
    "            labels = torch.add(labels, -1)\n",
    "            # max returns (value ,index)\n",
    "            # predicted = torch.argmax(outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_correct_array, n_wrong_array = countPredictedLetters(labels.to(device), predicted.to(device), n_correct_array, n_wrong_array)\n",
    "\n",
    "        # Save confusion matrix to Tensorboard\n",
    "        writer.add_figure(f\"Confusion matrix testing from: {FILE}\", createConfusionMatrix(test_loader, model))\n",
    "        writer.close()\n",
    "\n",
    "        counter = 0\n",
    "        n_correct = 0\n",
    "        n_wrong = 0\n",
    "        for letter in all_classes:\n",
    "            outputAcc(n_correct_array[counter], n_wrong_array[counter], letter)\n",
    "            n_correct += n_correct_array[counter]\n",
    "            n_wrong += n_wrong_array[counter]\n",
    "            counter += 1\n",
    "        outputAcc(n_correct, n_wrong, \"all\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function to use all of the functions of above"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = ConvNet().to(device)\n",
    "    train_loader, test_loader = dataloaderSetup()\n",
    "    if load_model_from_file == 1:\n",
    "        model = load_model(model)\n",
    "    else:\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        model = trainingPhase(model, criterion, optimizer, train_loader)\n",
    "\n",
    "    testingPhase(model, test_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}