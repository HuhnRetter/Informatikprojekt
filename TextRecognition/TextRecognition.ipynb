{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.color\n",
    "import torch\n",
    "from skimage import color\n",
    "from skimage import draw\n",
    "from skimage import io\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "\n",
    "import LetterNeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "setting for the TextRecognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_classes = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\",\n",
    "               \"G\", \"H\", \"I\", \"J\", \"K\", \"L\",\n",
    "               \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\",\n",
    "               \"S\", \"T\", \"U\", \"V\", \"W\", \"X\",\n",
    "               \"Y\", \"Z\"]\n",
    "\n",
    "FILETEXTTEST = \"./testimages/Blacktext/Test.png\"\n",
    "FILENEURALNET = \"LetterNeuralNetNE5BS26LR0001LetterNeuralNetACC92.pth\"\n",
    "# following parameters need to be customized to the letter size\n",
    "area_size_param = 500 # everything under the area_size will be not classified as a possible letter\n",
    "# -> this used to not have the holes of for example A to be classified as a letter\n",
    "padding = 10 # corresponding to the padding the guessed letter can change, because the training images also had a white border around the letters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "reading and modifying the image to be used in letter recognition,\n",
    "loading the trained model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setup():\n",
    "    \"\"\"reads an image from a given Path\n",
    "\n",
    "    :return: returns img as ndarray\n",
    "    \"\"\"\n",
    "    img = io.imread(FILETEXTTEST)\n",
    "    print(type(img))\n",
    "    return img\n",
    "\n",
    "def setupImage(img):\n",
    "    \"\"\"does multiple modification to the original img\n",
    "\n",
    "    converts the img to a grayscale image\n",
    "    blurs the img to get better bounding box results\n",
    "    inverts the img, so it can be used by the function measure.find_contours\n",
    "\n",
    "    :param img: image as ndarray\n",
    "    :return: returns the modified image as ndarray\n",
    "    \"\"\"\n",
    "    # remove alpha channel\n",
    "    try:\n",
    "        gray_img = color.rgba2rgb(img)\n",
    "        gray_img = color.rgb2gray(gray_img)\n",
    "    except Exception as e:\n",
    "        gray_img = color.rgb2gray(img)\n",
    "\n",
    "    # showimage(gray_img)\n",
    "    blur = gray_img\n",
    "    # showimage(blur)\n",
    "    # invert\n",
    "    th3 = skimage.util.invert(blur)\n",
    "    # showimage(th3)\n",
    "    return th3\n",
    "\n",
    "def setupModel():\n",
    "    \"\"\"loads the model from the given path\n",
    "\n",
    "    :return: returns the loaded model of type LetterNeuralNet.ConvNet\n",
    "    \"\"\"\n",
    "    model = LetterNeuralNet.ConvNet()\n",
    "    model.load_state_dict(torch.load(FILENEURALNET))\n",
    "    model.eval()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "helper functions for determining where the letters are located and draw a bounding box"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def showimage(img):\n",
    "    \"\"\"shows given image until ESC is pressed\n",
    "\n",
    "    :param img: image as ndarray\n",
    "    \"\"\"\n",
    "    while (1):\n",
    "        cv2.imshow('text', img)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "def getContourArea(cnt):\n",
    "    \"\"\"gets the Area of the Bounding box\n",
    "\n",
    "    :param cnt: is the contours of a possible letter of type ndarray\n",
    "    :return: returns area of the Bounding box\n",
    "    \"\"\"\n",
    "    x, w, y, h = getBoundingBox(cnt)\n",
    "    return (w - x) * (h - y)\n",
    "\n",
    "def getBoundingBox(cnt):\n",
    "    \"\"\"gets the bounding box of the given contour\n",
    "\n",
    "    :param cnt: is the contours of a possible letter of type ndarray\n",
    "    :return: returns an interval of the bounding box in form of four variables -> x, xmax, y, ymax\n",
    "    \"\"\"\n",
    "    x = np.min(cnt[:, 0])\n",
    "    xmax = np.max(cnt[:, 0])\n",
    "    y = np.min(cnt[:, 1])\n",
    "    ymax = np.max(cnt[:, 1])\n",
    "    return x, xmax, y, ymax\n",
    "\n",
    "def getCrop(img, x, y, xmax, ymax):\n",
    "    \"\"\"gets a cropped image for the given coordinates\n",
    "\n",
    "    :param img: image as ndarray\n",
    "    :param x: min value of x-coordinate of type int\n",
    "    :param y: min value of y-coordinate of type int\n",
    "    :param xmax: max value of x-coordinate of type int\n",
    "    :param ymax: max value of y-coordinate of type int\n",
    "    :return: returns the cropped image as ndarray\n",
    "    \"\"\"\n",
    "    return img[x:xmax, y:ymax]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function to determine the Bounding box of letters and locating letters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def drawBondingBox(img):\n",
    "    \"\"\"draws a bonding Box for each letter\n",
    "\n",
    "    :param img: image as ndarray\n",
    "    :return: returns the img with drawn bonding boxes\n",
    "    \"\"\"\n",
    "    model = setupModel()\n",
    "    th3 = setupImage(img)\n",
    "    contours = measure.find_contours(th3)\n",
    "    for cnt in contours:\n",
    "        area = getContourArea(cnt)\n",
    "        print(f\"boundingBoxArea for customizing in auto Bounding box:{area}\")\n",
    "        if area > area_size_param:\n",
    "            x, xmax, y, ymax = getBoundingBox(cnt)\n",
    "            x -= padding\n",
    "            y -= padding\n",
    "            xmax += padding\n",
    "            ymax += padding\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            xmax = int(xmax)\n",
    "            ymax = int(ymax)\n",
    "            letter = getLetter(th3, x, y, xmax, ymax, model)\n",
    "            try:\n",
    "                draw.set_color(img, draw.rectangle_perimeter((x, y), (xmax, ymax)), (0, 100, 0, 1))\n",
    "            except Exception as e:\n",
    "                draw.set_color(img, draw.rectangle_perimeter((x, y), (xmax, ymax)), (0, 100, 0))\n",
    "            cv2.putText(img, letter, (y, x - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 100, 0), 1)\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "image inside of the bounding box is cropped and then used as a input for the trained model,\n",
    "first the image is size_transformed, rotated and flipped to be the same as the trained image,\n",
    "\n",
    "then the tensor of the image is modified, so it can be used as a input\n",
    "first the tensor is 2 times unsqueeze to have the same size as the input tensors for training -> (batchsize, colorchannel, size, size)\n",
    "\n",
    "by creating a tensor from a grayscale image the size of the tensor is (size, size) because the grayscale image has only 1 color channel and it wouldnt change the resulting tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def useLetterRecognition(crop_img, model):\n",
    "    \"\"\"uses the cropped image to guess a letter with the given model\n",
    "\n",
    "    :param crop_img: cropped image as ndarray\n",
    "    :param model: loaded model of type LetterNeuralNet.ConvNet\n",
    "    :return: returns the guessed letter as a string\n",
    "    \"\"\"\n",
    "    crop_img = resize(crop_img, (28, 28), anti_aliasing=True)\n",
    "\n",
    "    numpy_crop_img = np.array(crop_img)\n",
    "    flipped_img = np.fliplr(numpy_crop_img)\n",
    "    turned_img = np.rot90(flipped_img)\n",
    "\n",
    "    crop_img_tensor = torch.from_numpy(turned_img.copy())\n",
    "    crop_img_tensor = crop_img_tensor.unsqueeze(dim=0)\n",
    "    c_crop_img_tensor = crop_img_tensor.unsqueeze(0)\n",
    "    c_crop_img_tensor = c_crop_img_tensor.float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(c_crop_img_tensor)\n",
    "    predicted = torch.argmax(outputs)\n",
    "    return all_classes[predicted]\n",
    "\n",
    "\n",
    "def getLetter(img, x, y, xmax, ymax, model):\n",
    "    \"\"\"gets a letter from an image and a given interval of a bounding box\n",
    "\n",
    "    :param img: image as ndarray\n",
    "    :param x: min value of x-coordinate of type int\n",
    "    :param y: min value of y-coordinate of type int\n",
    "    :param xmax: max value of x-coordinate of type int\n",
    "    :param ymax: max value of y-coordinate of type int\n",
    "    :param model: loaded model of type LetterNeuralNet.ConvNet\n",
    "    :return: returns the guessed letter as a string\n",
    "    \"\"\"\n",
    "    crop_img = getCrop(img, x, y, xmax, ymax)\n",
    "    return useLetterRecognition(crop_img, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "main function for using text recognition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img = setup()\n",
    "    img = drawBondingBox(img)\n",
    "    showimage(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}